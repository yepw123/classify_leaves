{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5a4045-8ef1-4d88-98a7-de4cf5f0a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "530f2a9a-97da-4acf-a68f-97b5abfcc239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_datadealer(annotations_file):\n",
    "    df = pd.read_csv(annotations_file)\n",
    "    label_list=df['label'].tolist()\n",
    "    labels = set(label_list)\n",
    "    label2num = {}\n",
    "    num2label = {}\n",
    "    i = 0\n",
    "    for x in labels:\n",
    "        label2num[x] = i\n",
    "        num2label[i] = x\n",
    "        i+=1\n",
    "    return label2num,num2label\n",
    "    \n",
    "#Adjust according to your data location\n",
    "label2num,num2label=pre_datadealer(\"H:/classify-leaves/classify-leaves/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70638c53-af5a-4c0e-9f49-fb537ab1e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_data(Dataset):\n",
    "    def __init__(self,annotations_file,img_dir):\n",
    "        super().__init__()\n",
    "        self.test=pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        rela_img_path = self.test.iloc[idx,0]\n",
    "        img_path = os.path.join(self.img_dir,rela_img_path).replace('\\\\','/')\n",
    "        img = transforms.ToTensor()(Image.open(img_path))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74779941-8ff5-4fc5-82e8-567c973b5045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 138/138 [02:17<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#Adjust according to your data location\n",
    "model_path='H:/classify-leaves/train_model.pt'\n",
    "sub_path= \"H:/classify-leaves/classify-leaves/sample_submission.csv\"\n",
    "img_dir = \"H:/classify-leaves/classify-leaves\"\n",
    "test_csv= \"H:/classify-leaves/classify-leaves/test.csv\"\n",
    "\n",
    "net = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "net.fc = nn.Linear(in_features=512, out_features=176, bias=True)\n",
    "net.to(torch.device('cuda'))\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "sub_dataset=Test_data(test_csv,img_dir)\n",
    "sub_iter=DataLoader(sub_dataset,batch_size=64,shuffle=False)\n",
    "res = pd.read_csv(sub_path)\n",
    "#res.insert(res.shape[1], 'label', 0)\n",
    "count = 0\n",
    "print('test start...')\n",
    "for X in tqdm(sub_iter):\n",
    "    X=X.to(d2l.try_gpu())\n",
    "    preds = net(X).detach().argmax(-1).to(torch.device('cpu')).numpy()\n",
    "    for num in preds:\n",
    "        res.iloc[count,1]=num2label[num]\n",
    "        count+=1\n",
    "res.to_csv(sub_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
